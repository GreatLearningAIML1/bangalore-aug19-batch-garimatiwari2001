{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_R10_Project2_Sarcasm Detection.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pp68FAQf9aMN"
      },
      "source": [
        "# Sarcasm Detection\n",
        " **Acknowledgement**\n",
        "\n",
        "Misra, Rishabh, and Prahal Arora. \"Sarcasm Detection using Hybrid Neural Network.\" arXiv preprint arXiv:1908.07414 (2019).\n",
        "\n",
        "**Required Files given in below link.**\n",
        "\n",
        "https://drive.google.com/drive/folders/1xUnF35naPGU63xwRDVGc-DkZ3M8V5mMk"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "S3Wj_mIZ8S3K"
      },
      "source": [
        "## Install `Tensorflow2.0` "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "v9kv9tyJ77eF"
      },
      "source": [
        "## Get Required Files from Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "D0O_n6OIEVyL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "9c621031-6090-45b3-edf5-71aa33df5c45"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iu7J7qt5UzJV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        },
        "outputId": "b7529a22-a6fe-4751-cfb7-68117c9f7ba8"
      },
      "source": [
        "import warnings\n",
        "import tensorflow as tf\n",
        "import pickle\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import preprocessing\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import json\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pprint\n",
        "from tensorflow.keras.layers import Bidirectional,LSTM,Dense,Dropout,BatchNormalization,Flatten,Input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import concatenate\n",
        "from numpy import array\n",
        "import nltk\n",
        "import re\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.stem import WordNetLemmatizer,PorterStemmer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize \n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h8aLqG3XU42E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2298d9d1-299c-4834-b694-c199c5bd37de"
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'2.2.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "WXYwajPeQbRq"
      },
      "source": [
        "#**## Reading and Exploring Data**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vAk6BRUh8CqL"
      },
      "source": [
        "## Read Data \"Sarcasm_Headlines_Dataset.json\". Explore the data and get  some insights about the data. ( 4 marks)\n",
        "Hint - As its in json format you need to use pandas.read_json function. Give paraemeter lines = True."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "StSLB-T8PuGr",
        "colab": {}
      },
      "source": [
        "df=pd.read_json(\"/content/drive/My Drive/Sarcasm Detection/Data/Sarcasm_Headlines_Dataset.json\",lines=True )"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YksEdfTdWNpg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "546832ff-c825-4832-985e-9a7e87ce03b2"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>article_link</th>\n",
              "      <th>headline</th>\n",
              "      <th>is_sarcastic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>https://www.huffingtonpost.com/entry/versace-b...</td>\n",
              "      <td>former versace store clerk sues over secret 'b...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>https://www.huffingtonpost.com/entry/roseanne-...</td>\n",
              "      <td>the 'roseanne' revival catches up to our thorn...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>https://local.theonion.com/mom-starting-to-fea...</td>\n",
              "      <td>mom starting to fear son's web series closest ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>https://politics.theonion.com/boehner-just-wan...</td>\n",
              "      <td>boehner just wants wife to listen, not come up...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>https://www.huffingtonpost.com/entry/jk-rowlin...</td>\n",
              "      <td>j.k. rowling wishes snape happy birthday in th...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                        article_link  ... is_sarcastic\n",
              "0  https://www.huffingtonpost.com/entry/versace-b...  ...            0\n",
              "1  https://www.huffingtonpost.com/entry/roseanne-...  ...            0\n",
              "2  https://local.theonion.com/mom-starting-to-fea...  ...            1\n",
              "3  https://politics.theonion.com/boehner-just-wan...  ...            1\n",
              "4  https://www.huffingtonpost.com/entry/jk-rowlin...  ...            0\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "z6pXf7A78E2H"
      },
      "source": [
        "## Drop `article_link` from dataset. ( 2 marks)\n",
        "As we only need headline text data and is_sarcastic column for this project. We can drop artical link column here."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VLSVsvrlP9qD",
        "colab": {}
      },
      "source": [
        "df1=df.drop(labels='article_link', axis=1,inplace=True)\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72n8hgLFWkL_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "outputId": "11a00a43-a146-4b03-cc4d-8aeadd7a42ee"
      },
      "source": [
        "df.head(2)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>headline</th>\n",
              "      <th>is_sarcastic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>former versace store clerk sues over secret 'b...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>the 'roseanne' revival catches up to our thorn...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            headline  is_sarcastic\n",
              "0  former versace store clerk sues over secret 'b...             0\n",
              "1  the 'roseanne' revival catches up to our thorn...             0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7vPXhyUNYObF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "912e616b-119c-4430-9cca-7c81eee18c20"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(26709, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-8P-zkAacDA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "4cc10ad2-565b-4c6e-cc2f-b72186b83cd0"
      },
      "source": [
        "df.dtypes"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "headline        object\n",
              "is_sarcastic     int64\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HyagoOLbYRiI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "dc263620-49cb-41f0-e93e-e8abc563ca5c"
      },
      "source": [
        "df['is_sarcastic'].value_counts()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    14985\n",
              "1    11724\n",
              "Name: is_sarcastic, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "D0h6IOxU8OdH"
      },
      "source": [
        "## Get the Length of each line and find the maximum length. ( 4 marks)\n",
        "As different lines are of different length. We need to pad the our sequences using the max length."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BRAsChZAQmr3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "34a8cabd-1be6-4c80-f3e2-a8cf86744f13"
      },
      "source": [
        "headline_max_length=max(len(txt) for txt in df['headline'])\n",
        "headline_max_length"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "254"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e3ZidJh9b3jT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "9b4c8b5f-0b94-476d-9f31-73fc6815185e"
      },
      "source": [
        "tokenizer = tf.keras.preprocessing.text.Tokenizer()\n",
        "tokenizer.fit_on_texts(df['headline']) #Fit it on Headlines\n",
        "input_seq = tokenizer.texts_to_sequences(df['headline'])\n",
        "input_seq[0:2] #Display some converted sentences"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[307, 15114, 678, 3336, 2297, 47, 381, 2575, 15115, 5, 2576, 8433],\n",
              " [3, 8434, 3337, 2745, 21, 1, 165, 8435, 415, 3111, 5, 257, 8, 1001]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CNN36RtXdW5d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8bc11f48-15a7-4009-aa2e-45fd893a38c5"
      },
      "source": [
        "vocab_size = len(tokenizer.word_index)\n",
        "print(vocab_size)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "29656\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E2qPge7Pez5m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "eeb01d53-7e8b-4d0e-fcc3-436909e94726"
      },
      "source": [
        "input_seq = tf.keras.preprocessing.sequence.pad_sequences(input_seq, \n",
        "                                                                   maxlen=headline_max_length,\n",
        "                                                                   padding='pre')\n",
        "print(input_seq.shape)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(26709, 254)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "VPPd0YuPXi2M"
      },
      "source": [
        "#**## Modelling**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "35abKfRx8as3"
      },
      "source": [
        "## Import required modules required for modelling."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DVel73hYEV4r",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, Flatten, Bidirectional, GlobalMaxPool1D\n",
        "from tensorflow.keras.models import Model, Sequential"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9ziybaD1RdD9"
      },
      "source": [
        "# Set Different Parameters for the model. ( 2 marks)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jPw9gAN_EV6m",
        "colab": {}
      },
      "source": [
        "max_features = 10000\n",
        "maxlen = headline_max_length\n",
        "embedding_size = 200"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9abSe-bM8fn9"
      },
      "source": [
        "## Apply Keras Tokenizer of headline column of your data.  ( 4 marks)\n",
        "Hint - First create a tokenizer instance using Tokenizer(num_words=max_features) \n",
        "And then fit this tokenizer instance on your data column df['headline'] using .fit_on_texts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0Ffi63KsST3P"
      },
      "source": [
        "# Define X and y for your model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wnjxBdqmSS4s",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        },
        "outputId": "e4bd554f-5e95-4a42-8be6-93931165a88c"
      },
      "source": [
        "X = tokenizer.texts_to_sequences(df['headline'])\n",
        "X = pad_sequences(X, maxlen = maxlen)\n",
        "y = np.asarray(df['is_sarcastic'])\n",
        "\n",
        "print(\"Number of Samples:\", len(X))\n",
        "print(X[0])\n",
        "print(\"Number of Labels: \", len(y))\n",
        "print(y[0])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of Samples: 26709\n",
            "[    0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0   307 15114   678  3336  2297    47   381  2575 15115     5\n",
            "  2576  8433]\n",
            "Number of Labels:  26709\n",
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wCHmQQuhfibI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X=input_seq\n",
        "y=np.asarray(df['is_sarcastic'])\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gUo0SdmAoj1n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X,\n",
        "    y,\n",
        "    test_size=0.2, \n",
        "    random_state=42\n",
        ")"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e4BTBLgnmrlb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4df2f607-bff3-42f1-bfb2-752eee674070"
      },
      "source": [
        "y_val.shape"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5342,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1YGt_kETsQEk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e9c4e498-fa29-4fea-920c-4319d78a3b95"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(21367, 254)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "WJLyKg-98rH_"
      },
      "source": [
        "## Get the Vocabulary size ( 2 marks)\n",
        "Hint : You can use tokenizer.word_index."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "q-2w0gHEUUIo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "79f95807-b4b6-4432-c22f-920ba5b8a7ad"
      },
      "source": [
        "vocab_size = len(tokenizer.word_index)\n",
        "print(vocab_size)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "29656\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5hjeMi40XcB1"
      },
      "source": [
        "#**## Word Embedding**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "bUF1TuQa8ux0"
      },
      "source": [
        "## Get Glove Word Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vq5AIfRtMeZh",
        "colab": {}
      },
      "source": [
        "glove_file = \"/content/drive/My Drive/Sarcasm Detection/Data/glove.6B.zip\""
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DJLX_n2WMecA",
        "colab": {}
      },
      "source": [
        "#Extract Glove embedding zip file\n",
        "from zipfile import ZipFile\n",
        "with ZipFile(glove_file, 'r') as z:\n",
        "  z.extractall()"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9IuXlu8-U3HG"
      },
      "source": [
        "# Get the Word Embeddings using Embedding file as given below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "elZ-T5aFGZmZ",
        "colab": {}
      },
      "source": [
        "EMBEDDING_FILE = './glove.6B.200d.txt'\n",
        "\n",
        "embeddings = {}\n",
        "for o in open(EMBEDDING_FILE):\n",
        "    word = o.split(\" \")[0]\n",
        "    # print(word)\n",
        "    embd = o.split(\" \")[1:]\n",
        "    embd = np.asarray(embd, dtype='float32')\n",
        "    # print(embd)\n",
        "    embeddings[word] = embd\n",
        "\n"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "bTPxveDmVCrA"
      },
      "source": [
        "# Create a weight matrix for words in training docs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xQgOhiywU9nU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "13895691-4979-45b1-b6b2-6024274b20d3"
      },
      "source": [
        "embedding_matrix = np.zeros((vocab_size+1, 200))\n",
        "\n",
        "for word, i in tokenizer.word_index.items():\n",
        "    embedding_vector = embeddings.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "\n",
        "len(embeddings.values())"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "400000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "u7IbWuEX82Ra"
      },
      "source": [
        "## Create and Compile your Model  ( 7 marks)\n",
        "Hint - Use Sequential model instance and then add Embedding layer, Bidirectional(LSTM) layer, then dense and dropout layers as required. \n",
        "In the end add a final dense layer with sigmoid activation for binary classification.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "d7jhsSgYXG4l",
        "colab": {}
      },
      "source": [
        "### Embedding layer for hint \n",
        "## model.add(Embedding(num_words, embedding_size, weights = [embedding_matrix]))\n",
        "### Bidirectional LSTM layer for hint \n",
        "## model.add(Bidirectional(LSTM(128, return_sequences = True)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8rQIPWJHpUBe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tf.keras.Sequential()"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJVwjeN0pV1j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.add(tf.keras.layers.Embedding(input_dim=vocab_size+1,\n",
        "                  output_dim=embedding_size,\n",
        "                  weights=[embedding_matrix],\n",
        "                  trainable=False, mask_zero= True))"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_MUIk7vdg5yT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.add(tf.keras.layers.Dropout(0.2))\n",
        "model.add(tf.keras.layers.Bidirectional(LSTM(units=128,return_sequences=False),merge_mode='concat'))\n"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HCdJaacGqEqL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b7ad07c9-d851-413f-ae9f-b6618c052d91"
      },
      "source": [
        "model.output"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'bidirectional/Identity:0' shape=(None, 256) dtype=float32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4-eEunanqJGx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.add(tf.keras.layers.Dense(1,activation='sigmoid'))"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xq1yHwWhqP2y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fhkQADcbqoCq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        },
        "outputId": "e492a360-ed10-424a-e5f2-4e72df442937"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, None, 200)         5931400   \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, None, 200)         0         \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, 256)               336896    \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 257       \n",
            "=================================================================\n",
            "Total params: 6,268,553\n",
            "Trainable params: 337,153\n",
            "Non-trainable params: 5,931,400\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "IJFMxZwMWoTw"
      },
      "source": [
        "# Fit your model with a batch size of 100 and validation_split = 0.2. and state the validation accuracy ( 5 marks)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZpVkajCcWnRK",
        "colab": {}
      },
      "source": [
        "batch_size = 100\n",
        "epochs = 5\n",
        "\n",
        "## Add your code here ##"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n0ErE3BLmKaH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "outputId": "222683ac-73f4-4300-ddd1-230e920be048"
      },
      "source": [
        "model.fit(X_train,y_train,\n",
        "          epochs=5,\n",
        "          batch_size=100, validation_data=(X_val, y_val))"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "214/214 [==============================] - 215s 1s/step - loss: 0.4818 - accuracy: 0.7676 - val_loss: 0.4069 - val_accuracy: 0.8134\n",
            "Epoch 2/5\n",
            "214/214 [==============================] - 213s 997ms/step - loss: 0.3584 - accuracy: 0.8395 - val_loss: 0.3372 - val_accuracy: 0.8529\n",
            "Epoch 3/5\n",
            "214/214 [==============================] - 212s 993ms/step - loss: 0.2956 - accuracy: 0.8731 - val_loss: 0.3124 - val_accuracy: 0.8673\n",
            "Epoch 4/5\n",
            "214/214 [==============================] - 213s 997ms/step - loss: 0.2561 - accuracy: 0.8919 - val_loss: 0.3119 - val_accuracy: 0.8622\n",
            "Epoch 5/5\n",
            "214/214 [==============================] - 213s 993ms/step - loss: 0.2241 - accuracy: 0.9093 - val_loss: 0.3037 - val_accuracy: 0.8735\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fb7600895f8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s30jaAS1Oxob",
        "colab_type": "text"
      },
      "source": [
        "Validation Accuracy with Embedding size of 200 and RNN Units of 128 is 87.35"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ffEM9RlzOnBM",
        "colab_type": "text"
      },
      "source": [
        "# Model 2- Glove Embedding of 300, With 256 Memory Size"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6tF3vRSCOlIH",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g6_MJYLOqflo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EMBEDDING_FILE = './glove.6B.300d.txt'\n",
        "\n",
        "embeddings = {}\n",
        "for o in open(EMBEDDING_FILE):\n",
        "    word = o.split(\" \")[0]\n",
        "    # print(word)\n",
        "    embd = o.split(\" \")[1:]\n",
        "    embd = np.asarray(embd, dtype='float32')\n",
        "    # print(embd)\n",
        "    embeddings[word] = embd"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6DBndY2XNrXW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7f41a716-70b4-4de0-ea0f-821e2f62284c"
      },
      "source": [
        "embedding_matrix = np.zeros((vocab_size+1, 300))\n",
        "\n",
        "for word, i in tokenizer.word_index.items():\n",
        "    embedding_vector = embeddings.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "\n",
        "len(embeddings.values())"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "400000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RyZwZJgVNw7Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model2 = tf.keras.Sequential()\n",
        "model2.add(tf.keras.layers.Embedding(input_dim=vocab_size+1,\n",
        "                  output_dim=300,\n",
        "                  weights=[embedding_matrix],\n",
        "                  trainable=False, mask_zero= True))\n",
        "model2.add(tf.keras.layers.Dropout(0.2))\n",
        "model2.add(tf.keras.layers.Bidirectional(LSTM(units=256,return_sequences=False),merge_mode='concat'))\n",
        "model2.add(tf.keras.layers.Dense(1,activation='sigmoid'))\n",
        "model2.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nRm5h0Az2ieX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        },
        "outputId": "06dd0fd7-6363-4587-d306-f41136e62d9e"
      },
      "source": [
        "model2.summary()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, None, 300)         8897100   \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, None, 300)         0         \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 512)               1140736   \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 513       \n",
            "=================================================================\n",
            "Total params: 10,038,349\n",
            "Trainable params: 1,141,249\n",
            "Non-trainable params: 8,897,100\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LPE8IAH1OPTE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "outputId": "baa42157-8dcf-42c8-9278-6642ac15c04f"
      },
      "source": [
        "model2.fit(X_train,y_train,\n",
        "          epochs=5,\n",
        "          batch_size=100, validation_data=(X_val, y_val))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "214/214 [==============================] - 219s 1s/step - loss: 0.4574 - accuracy: 0.7815 - val_loss: 0.3763 - val_accuracy: 0.8297\n",
            "Epoch 2/5\n",
            "214/214 [==============================] - 217s 1s/step - loss: 0.3308 - accuracy: 0.8523 - val_loss: 0.3276 - val_accuracy: 0.8504\n",
            "Epoch 3/5\n",
            "214/214 [==============================] - 218s 1s/step - loss: 0.2602 - accuracy: 0.8915 - val_loss: 0.3089 - val_accuracy: 0.8675\n",
            "Epoch 4/5\n",
            "214/214 [==============================] - 220s 1s/step - loss: 0.2058 - accuracy: 0.9123 - val_loss: 0.2931 - val_accuracy: 0.8783\n",
            "Epoch 5/5\n",
            "214/214 [==============================] - 220s 1s/step - loss: 0.1547 - accuracy: 0.9399 - val_loss: 0.3389 - val_accuracy: 0.8695\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fb7040fa0f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BbkXFpjcg_d_",
        "colab_type": "text"
      },
      "source": [
        "Validation Accuracy with Embedding size of 300 and RNN Units of 256 is 86.95"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dN_2jmSb5QpO",
        "colab_type": "text"
      },
      "source": [
        "# Model 3- Glove Embedding of 300, With 128 Memory Size"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ofFzHPq5YTk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model3 = tf.keras.Sequential()\n",
        "model3.add(tf.keras.layers.Embedding(input_dim=vocab_size+1,\n",
        "                  output_dim=300,\n",
        "                  weights=[embedding_matrix],\n",
        "                  trainable=False, mask_zero= True))\n",
        "model3.add(tf.keras.layers.Dropout(0.2))\n",
        "model3.add(tf.keras.layers.Bidirectional(LSTM(units=128,return_sequences=False),merge_mode='concat'))\n",
        "model3.add(tf.keras.layers.Dense(1,activation='sigmoid'))\n",
        "model3.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GHIaVeGR5ury",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        },
        "outputId": "7cd2823e-744f-47bc-b4f5-33bcccbf8698"
      },
      "source": [
        "model3.summary()"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (None, None, 300)         8897100   \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, None, 300)         0         \n",
            "_________________________________________________________________\n",
            "bidirectional_2 (Bidirection (None, 256)               439296    \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 257       \n",
            "=================================================================\n",
            "Total params: 9,336,653\n",
            "Trainable params: 439,553\n",
            "Non-trainable params: 8,897,100\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHGmbgNV6C7h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 554
        },
        "outputId": "7948b486-91d2-416c-8dfa-45965070c23c"
      },
      "source": [
        "model3.fit(X_train,y_train,\n",
        "          epochs=15,\n",
        "          batch_size=100, validation_data=(X_val, y_val))"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "214/214 [==============================] - 221s 1s/step - loss: 0.4555 - accuracy: 0.7820 - val_loss: 0.3657 - val_accuracy: 0.8321\n",
            "Epoch 2/15\n",
            "214/214 [==============================] - 215s 1s/step - loss: 0.3342 - accuracy: 0.8538 - val_loss: 0.3265 - val_accuracy: 0.8568\n",
            "Epoch 3/15\n",
            "214/214 [==============================] - 218s 1s/step - loss: 0.2734 - accuracy: 0.8828 - val_loss: 0.3019 - val_accuracy: 0.8723\n",
            "Epoch 4/15\n",
            "214/214 [==============================] - 218s 1s/step - loss: 0.2246 - accuracy: 0.9078 - val_loss: 0.3075 - val_accuracy: 0.8712\n",
            "Epoch 5/15\n",
            "214/214 [==============================] - 217s 1s/step - loss: 0.1807 - accuracy: 0.9272 - val_loss: 0.3057 - val_accuracy: 0.8751\n",
            "Epoch 6/15\n",
            "214/214 [==============================] - 215s 1s/step - loss: 0.1384 - accuracy: 0.9460 - val_loss: 0.3160 - val_accuracy: 0.8819\n",
            "Epoch 7/15\n",
            "214/214 [==============================] - 215s 1s/step - loss: 0.1087 - accuracy: 0.9584 - val_loss: 0.3286 - val_accuracy: 0.8778\n",
            "Epoch 8/15\n",
            "214/214 [==============================] - 214s 999ms/step - loss: 0.0807 - accuracy: 0.9715 - val_loss: 0.3561 - val_accuracy: 0.8845\n",
            "Epoch 9/15\n",
            "214/214 [==============================] - 218s 1s/step - loss: 0.0650 - accuracy: 0.9763 - val_loss: 0.3796 - val_accuracy: 0.8778\n",
            "Epoch 10/15\n",
            "214/214 [==============================] - 219s 1s/step - loss: 0.0493 - accuracy: 0.9827 - val_loss: 0.3968 - val_accuracy: 0.8845\n",
            "Epoch 11/15\n",
            "214/214 [==============================] - 220s 1s/step - loss: 0.0405 - accuracy: 0.9869 - val_loss: 0.4331 - val_accuracy: 0.8735\n",
            "Epoch 12/15\n",
            "214/214 [==============================] - 217s 1s/step - loss: 0.0321 - accuracy: 0.9900 - val_loss: 0.4313 - val_accuracy: 0.8753\n",
            "Epoch 13/15\n",
            "214/214 [==============================] - 216s 1s/step - loss: 0.0244 - accuracy: 0.9927 - val_loss: 0.4445 - val_accuracy: 0.8781\n",
            "Epoch 14/15\n",
            "214/214 [==============================] - 214s 1s/step - loss: 0.0220 - accuracy: 0.9937 - val_loss: 0.4758 - val_accuracy: 0.8774\n",
            "Epoch 15/15\n",
            "214/214 [==============================] - 215s 1s/step - loss: 0.0211 - accuracy: 0.9932 - val_loss: 0.4861 - val_accuracy: 0.8794\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fb6b5675ba8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8VRsPwcX-ZcI",
        "colab_type": "text"
      },
      "source": [
        "Validation Accuracy with Embedding size of 300 and RNN Units of 128 is 87.94"
      ]
    }
  ]
}